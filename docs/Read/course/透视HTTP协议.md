# 透视 HTTP 协议笔记



## 课程目录

破冰篇

时势与英雄：HTTP 协议的前世今生

HTTP 是什么？HTTP 又不是什么

HTTP 世界全览（上）：与 HTTP 相关的各种概念

HTTP 世界全览（下）：与 HTTP 相关的各种协议

”七层“和”四层“是什么？”五层“”六层“哪去了？

域名里有哪些门道？

自己动手，搭建HTTP实验环境

基础篇

键入网址后按下回车，后面究竟发生了什么？

HTTP报文是什么样子的？

应该如何理解请求方法？

你能写出正确的网址吗？

响应状态码该怎么用？

HTTP 协议有哪些特点？

HTTP 有哪些优点和缺点？

进阶篇

海纳百川：HTTP 的实体数据

把大象装进冰箱：HTTP 传输大文件的方法

排队也要讲效率：HTTP 的连接管理

四通八达：HTTP 重定向和跳转

让我知道你是谁：HTTP 的 Cookie 机制

生鲜速递：HTTP 的缓存控制

良心中间商：HTTP 的代理服务

冷链周转：HTTP 的缓存代理

安全篇

HTTPS 是什么？SSL/TLC 又是什么？

固若金汤的根本（上）：对称加密与非对称加密

固若金汤的根本（下）：数字签名与证书

信任始于握手：TLS1.2 连接过程解析

更好更快的握手：TLS1.3 特性解析

连接太慢该怎么办：HTTPS 的优化

我应该迁移到 HTTPS 吗

飞翔篇

时代之风（上）：HTTP/2 特性概览

时代之风（下）：HTTP/2 内核剖析

未来之路：HTTP/3 展望

我应该迁移到 HTTP/2 吗？

探索篇

Nginx：高性能的 Web 服务器

OpenResty：更灵活的 Web 服务器

WAF：保护我们的网络服务

CDN：加速我们的网络服务

WebSocket：沙盒里的 TCP

总结篇

HTTP 性能优化面面观（上）

HTTP 性能优化面面观（下）



## HTTP 的前世今生

### 史前年代

20 世纪 60 年代，美国国防部高等研究计划署（ARPA）建立了 ARPA 网，它有四个分布在各地的节点，被认为是如今互联网的“始祖”。

70 年代，基于对 ARPA 网的实践和思考，研究人员发明出了著名的 TCP/IP 协议。并在 80 年代中期进入了 UNIX 系统内核，促使更多的计算机接入了互联网

### 创世纪

1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·博纳斯·李发表了一篇论文，提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术

1. URI：即统一资源标识符，作为互联网上资源的唯一身份；
2. HTML：即超文本标记语言，描述超文本文档；
3. HTTP：即超文本传输协议，用来传输超文本；

基于它们，就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，蒂姆把这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web

### HTTP/0.9

它只支持纯文本格式，以及只允许“GET”请求，并且在相应请求之后立即关闭连接，功能有限

“把简单的系统变复杂”，要比“把复杂的系统变简单”容易的多

### HTTP/1.0

1993 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器，随后又在 1995 年开发出了服务器软件 Apache，简化了 HTTP 服务器的搭建工作

同一时期，1992 年发明了 JPEG 图像格式，1995 年发明了 MP3 音乐格式

HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如：

1. 增加了 HEAD、POST 等新方法
2. 增加了响应状态码，标记可能的错误原因；
3. 引入了协议版本号概念；
4. 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和相应更加灵活；
5. 传输的数据不再仅限于文本

但 HTTP/1.0 并不是一个“标准”，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个“备忘录”

### HTTP/1.1

网景与微软的“浏览器大战”推动了 Web 的发展，在“浏览器大战”结束之后的 1999 年，HTTP/1.1 发布了 RFC 文档，编号为 2616，成为“正式的标准”。这意味着今后互联网上所有的浏览器、服务器、网关、代理等等，只要用到 HTTP 协议，就必须严格遵守这个标准，相当于是互联网世界的一个“立法”

HTTP/1.1 的主要变更有：

1. 增加了 PUT、DELETE 等新的方法；
2. 增加了缓存管理和控制；
3. 明确了连接管理，允许持久连接；
4. 允许相应数据分块（chunked），李渔传输大文件；
5. 强制要求 Host 头，让互联网主机托管成为可能

### HTTP/2

2015 年发布 HTTP/2，RFC 编号 7540，由 Google 推动，将自家的 SPDY 协议腿上标准的宝座，称为了 HTTP/2 协议

HTTP/2 的做东充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容 HTTP/1.1 的同时在性能上做了很大的改善，主要特点有：

1. 二进制协议，不再是纯文本；
2. 可发起多个请求，废弃了 1.1 里的管道；
3. 使用专用算法压缩头部，减少数据传输量；
4. 允许服务器主动向客户端推送数据；
5. 增强了安全性，“事实上”要求加密通信

虽然 HTTP/2 推出已经 5 个年头了，但因为 HTTP/1.1 实在太过经典和强势，目前普及率还比较低

### HTTP/3

Google 发明了一个新的协议，叫做 QUIC，目前 HTTP/3 在标准化指定阶段，也许要两三年后正式发布

### 历史回顾

1. HTTP 协议始于三十年前蒂姆·博纳斯·李的一篇论文
2. HTTP/0.9 是个简单的文本协议，只能获取文本资源；
3. HTTP/1.0 确立了大部分现有使用的技术，但它不是正式标准；
4. HTTP/1.1 是目前互联网上使用最广泛的协议，功能也非常完善；
5. HTTP/2 基于 Google 的 SPDY 协议，注重性能改善，但普及度不高
6. HTTP/3 基于 Google 的 QUIC 协议，是将来的发展方向



## HTTP 是什么？HTTP 又不是什么？

HTTP 就是超文本传输协议。它是协议、也是传输、又是超文本。但它不是互联网、不是编程语言、不是HTML、不是一个孤立的协议

1. HTTP 是一个用在计算机世界里的协议，它确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。
2. HTTP 专门用来在两点之间传输数据，不能用于广播、寻址或路由。
3. HTTP 传输的是文字、图片、音频、视频等超文本数据。
4. HTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。



互联网（Internet）是遍布于全球的许多网络互相连接而形成的一个巨大的国际网络，在它上面存放着各式各样的资源，也对应着各式各样的协议，例如超文本资源使用 HTTP，普通文件使用 FTP，电子邮件使用 SMTP 和 POP3 等。

但毫无疑问，HTTP 是构建互联网的一块重要拼图，而且是占比最大的那一块。





## HTTP 世界全览：与 HTTP 相关的各种概念

![HTTP世界](https://s2.loli.net/2022/03/29/S7dwkq48TYK5m1z.png)

这张图左边的部分是与 HTTP 有关系的各种协议，比较偏向于理论；而右边的部分是与 HTTP 有关系的各种应用技术，偏向于实际应用。

先看右边这部分

![与HTTP相关的各种概念](https://s2.loli.net/2022/03/29/6YShwn5WuFgRMCO.png)

互联网的正式名称是 Internet，里面存储着无穷无尽的信息资源，我们通常所说的 **上网** 实际上访问的只是互联网的一个子集 「万维网（World Wide Web）」，**它基于 HTTP 协议** ，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。

互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。

1. 互联网上绝大部分资源都使用 HTTP 协议传输；
2. 浏览器是 HTTP 协议里的请求方，即 User Agent；
3. 服务器是 HTTP 协议里的应答方，常用的有 Apache 和 Nginx；
4. CDN 位于浏览器和服务器之间，主要起到缓存加速的作用；
5. 爬虫是另一类 User Agent，是自动访问网络资源的程序

## HTTP 世界全览：与 HTTP 相关的各种协议

在上一讲中，我介绍了与 HTTP 相关的浏览器、服务器、CDN、网络爬虫等应用技术。

今天要讲的则是比较偏向于理论的各种 HTTP 相关协议，重点是 TCP/IP、DNS、URI、HTTPS 等，希望能够帮你理清楚它们与 HTTP 的关系。

![HTTP 相关协议](https://s2.loli.net/2022/03/29/JxZCY3jEtpvcLR1.png)

#### TCP/IP

TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 **TCP** 和 **IP** ，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。

这个协议栈有四层，最上层是 **应用层**，最下层是 **链接层** ，TCP 和 IP 则在中间：**TCP 属于传输层，IP 属于网际层** 。

**IP 协议** 是 **Internet Protocol** 的缩写，**主要目的是解决寻址和路由问题，以及如何在两点间传送数据包** 。IP 协议使用 **IP 地址** 的概念来定位互联网上的每一台计算机。可以对比一下现实中的电话系统，你拿着的手机相当于互联网上的计算机，而要打电话就必须接入电话网，由通信公司给你分配一个号码，这个号码就相当于 IP 地址。

现在我们使用的 IP 协议大多数是 v4 版，地址是四个用 `.` 分隔的数字，例如 `192.168.0.1` ，总共有 2^32，大约 42 亿个可以分配的地址。看上去好像很多，但互联网的快速发展让地址的分配管理很快就捉襟见肘。所以，就又出现了 v6 版，使用 8 组 `:` 分隔的数字作为地址，容量扩大了很多，有 2^128 个，在未来的几十年里应该是足够用了。

**TCP 协议**是 `Transmission Control Protocol` 的缩写，意思是 **传输控制协议** ，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。

#### DNS

DNS 域名是 IP 地址的等价替代，需要用域名解析实现到 IP 地址的映射；

#### URI/URL

DNS 和 IP 地址只是标记了互联网上的主机，但主机上有那么多文本、图片、页面，到底要找哪一个呢？

所以就出现了 URI（Uniform Resource Identifier），中文名称是 **统一资源标识符** ，使用它就能够唯一地标记互联网上资源。

URI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， **统一资源定位符** ，也就是我们俗称的「网址」，它实际上是 URI 的一个子集，不过因为这两者几乎是相同的，差异不大，所以通常不会做严格的区分。

URI 主要有三个基本的部分构成：

1. 协议名：即访问该资源应当使用的协议，在这里是 `http`；
2. 主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是 `nginx.org`；
3. 路径：即资源在主机上的位置，使用 `/` 分隔多级目录，在这里是 `/en/download.html` 

#### HTTPS

HTTPS 就相当于这个比喻中的「火星文」，它的全称是 **HTTP over SSL/TLS** ，也就是运行在 SSL/TLS 协议上的 HTTP。

注意它的名字，这里是 SSL/TLS，而不是 TCP/IP，它是一个 **负责加密通信的安全协议** ，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层。

因为 HTTPS 相当于 `HTTP+SSL/TLS+TCP/IP` ，其中的 `HTTP` 和 `TCP/IP` 我们都已经明白了，只要再了解一下 SSL/TLS，HTTPS 也就能够轻松掌握。

SSL 的全称是 `Secure Socket Layer` ，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即 `Transport Layer Security`，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。

SSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲。

#### 代理

代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为 **中转站** ，既可以转发客户端的请求，也可以转发服务器的应答。

代理有很多的种类，常见的有：

1. 匿名代理：完全 **隐匿** 了被代理的机器，外界看到的只是代理服务器；
2. 透明代理：顾名思义，它在传输过程中是 **透明开放** 的，外界既知道代理，也知道客户端；
3. 正向代理：靠近客户端，代表客户端向服务器发送请求；
4. 反向代理：靠近服务器端，代表服务器响应客户端的请求；

这次我介绍了与 HTTP 相关的各种协议，在这里简单小结一下今天的内容。

1. TCP/IP 是网络世界最常用的协议，HTTP 通常运行在 TCP/IP 提供的可靠传输基础上；
2. DNS 域名是 IP 地址的等价替代，需要用域名解析实现到 IP 地址的映射；
3. URI 是用来标记互联网上资源的一个名字，由 `协议名 + 主机名 + 路径` 构成，俗称 URL；
4. HTTPS 相当于 `HTTP+SSL/TLS+TCP/IP` ，为 HTTP 套了一个安全的外壳；
5. 代理是 HTTP 传输过程中的中转站，可以实现缓存加速、负载均衡等功能。



## 常说的四层和七层到底是什么？五层、六层哪去了？

### TCP/IP 网络分层模型

![TCP/IP 网络分层模型](https://s2.loli.net/2022/03/29/l3m8kJDCf5ZdjSh.png)

TCP/IP 协议总共有四层，就像搭积木一样，每一层需要下层的支撑，同时又支撑着上层，任何一层被抽掉都可能会导致整个协议栈坍塌。

第一层叫 **链接层** （link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 **MAC 地址来标记网络上的设备** ，所以有时候也叫 MAC 层。

第二层叫 **网际层** 或者 **网络互连层** （internet layer），IP 协议就处在这一层。因为 IP 协议定义了 **IP 地址** 的概念，所以就可以在 **链接层** 的基础上，**用 IP 地址取代 MAC 地址** ，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再「翻译」成 MAC 地址就可以了。

第三层叫 **传输层**（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间可靠地传输，是 TCP 协议工作的层次，另外还有它的一个小伙伴 UDP。

**TCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据** ，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的字节流，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。

关于 TCP 和 UDP 可以展开讨论的话题还有很多，比如最经典的「三次握手」和「四次挥手」，一时半会很难说完，好在与 HTTP 的关系不是太大，以后遇到了再详细讲解。

协议栈的第四层叫 **应用层** （application layer），由于下面的三层把基础打得非常好，所以在这一层就百花齐放了，有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP。

- MAC 层的传输单位是帧（frame）
- IP 层的传输单位是包（packet）
- TCP 层的传输单位是段（segment）
- HTTP 的传输单位则是消息或报文（message）

### OSI 网络分层模型

第二个网络分层模型：**OSI** ，全称是 **开放式系统互联通信参考模型** （Open System Interconnection Reference Model）。

![OSI 网络分层模型](https://s2.loli.net/2022/03/29/pLzfhyXKHosTR6Z.png)

1. 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等；
2. 第二层：数据链路层，它基本相当于 TCP/IP 的链接层；
3. 第三层：网络层，相当于 TCP/IP 里的网际层；
4. 第四层：传输层，相当于 TCP/IP 里的传输层；
5. 第五层：会话层，维护网络中的连接状态，即保持会话和同步；
6. 第六层：表示层，把数据转换为合适、可理解的语法和语义；
7. 第七层：应用层，面向具体的应用传输数据。

不过国际标准组织心里也很清楚，TCP/IP 等协议已经在许多网络上实际运行，再推翻重来是不可能的。所以，OSI 分层模型在发布的时候就明确地表明是一个「参考」，不是强制标准，意思就是说，「你们以后该干什么还干什么，我不管，但面子上还是要按照我说的来」。



### 两个分层模型的映射关系

现在我们有了两个网络分层模型：TCP/IP 和 OSI，新的问题又出现了，一个是四层模型，一个是七层模型，这两者应该如何互相映射或者说互相解释呢？

好在 OSI 在设计之初就参考了 TCP/IP 等多个协议，可以比较容易但不是很精确地实现对应关系。

![两个分层模型的映射关系](https://s2.loli.net/2022/03/29/NGdR1VHo4LeXDb7.png)

1. 第一层：物理层，TCP/IP 里无对应；
2. 第二层：数据链路层，对应 TCP/IP 的链接层；
3. 第三层：网络层，对应 TCP/IP 的网际层；
4. 第四层：传输层，对应 TCP/IP 的传输层；
5. 第五、六、七层：统一对应到 TCP/IP 的应用层。

### TCP/IP 协议栈的工作方式

你可以把 HTTP 利用 TCP/IP 协议栈传输数据想象成一个发快递的过程。

![TCP/IP 协议栈的工作方式](https://s2.loli.net/2022/03/29/quf6FtHB5mK1dk9.png)

这次我们学习了 HTTP 所在的网络分层模型，它是工作中常用的交流语言，在这里简单小结一下今天的内容。

1. TCP/IP 分为四层，核心是二层的 IP 和三层的 TCP，HTTP 在第四层；
2. OSI 分为七层，基本对应 TCP/IP，TCP 在第四层，HTTP 在第七层；
3. OSI 可以映射到 TCP/IP，但这期间一、五、六层消失了；
4. 日常交流的时候我们通常使用 OSI 模型，用四层、七层等术语；
5. HTTP 利用 TCP/IP 协议栈逐层打包再拆包，实现了数据传输，但下面的细节并不可见。

有一个辨别四层和七层比较好的（但不是绝对的）小窍门，**两个凡是**：

- 凡是由操作系统负责处理的就是四层或四层以下，
- 否则，凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。



## 域名里有哪些门道



### 域名的形式

域名是一个有层次的结构，是一串用 `.` 分隔的多个单词，最右边的被称为 **顶级域名**，然后是 **二级域名** ，层级关系向左依次降低。

域名不仅能够代替 IP 地址，还有许多其他的用途。

在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务，比如在 Nginx 里就会使用 `server_name` 指令：

```nginx
server {
    listen 80;
    server_name time.geekbang.org; # 主机名是 time.geekbang.org
}
```

### 域名的解析

就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是 **域名解析** 。

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：

1. 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回 `com`、`net`、`cn` 等顶级域名服务器的 IP 地址；
2. 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；
3. 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 `www.apple.com` 的 IP 地址。

![DNS服务器](https://s2.loli.net/2022/03/29/MJiKOApEuLIqsoN.png)

在这里根域名服务器是关键，它必须是众所周知的，否则下面的各级服务器就无从谈起了。目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到。

例如，你要访问 `www.apple.com` ，就要进行下面的三次查询：

1. 访问根域名服务器，它会告诉你 `com` 顶级域名服务器的地址；
2. 访问 `com` 顶级域名服务器，它再告诉你 `apple.com` 域名服务器的地址；
3. 最后访问 `apple.com` 域名服务器，就得到了 `www.apple.com` 的地址。

所以在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是 **缓存** 

这些「野生」服务器被称为「非权威域名服务器」，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址

比较知名的 DNS 有 Google 的 `8.8.8.8`，Microsoft 的 `4.2.2.1` ，还有 CloudFlare 的 `1.1.1.1` 等等

另外，操作系统里还有一个特殊的 **主机映射** 文件，通常是一个可编辑的文本，在 Linux 里是 `/etc/hosts`，在 Windows 里是 `C:\WINDOWS\system32\drivers\etc\hosts` ，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。

下面的这张图比较完整地表示了现在的 DNS 架构。

![DNS 架构](https://s2.loli.net/2022/03/29/Qsh6wrFV5puOdLf.png)



### 域名的新玩法

可信的 DNS

- 重定向、名字服务器、基于域名实现的负载均衡

不怀好意的 DNS

- **域名屏蔽** ，对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站；
- **域名劫持** ，也叫 **域名污染**，你要访问 A 网站，但 DNS 给了你 B 网站。

这次我们学习了与 HTTP 协议有重要关系的域名和 DNS，在这里简单小结一下今天的内容：

1. 域名使用字符串来代替 IP 地址，方便用户记忆，本质上一个名字空间系统；
2. DNS 就像是我们现实世界里的电话本、查号台，统管着互联网世界里的所有网站，是一个超级大管家；
3. DNS 是一个树状的分布式查询系统，但为了提高查询效率，外围有多级的缓存；
4. 使用 DNS 可以实现基于域名的负载均衡，既可以在内网，也可以在外网



## 自己动手，搭建 HTTP 实验环境

回顾：

HTTP 协议诞生于 30 年前，设计之初的目的是用来传输纯文本数据。但由于形式灵活，搭配 URI、HTML 等技术能够把互联网上的资源都联系起来，构成一个复杂的超文本系统，让人们自由地获取信息，所以得到了迅猛发展。

HTTP 有多个版本，目前应用的最广泛的是 HTTP/1.1，它几乎可以说是整个互联网的基石。但 HTTP/1.1 的性能难以满足如今的高流量网站，于是又出现了 HTTP/2 和 HTTP/3。不过这两个新版本的协议还没有完全推广开。在可预见的将来，HTTP/1.1 还会继续存在下去。

HTTP 翻译成中文是 **超文本传输协议** ，是一个应用层的协议，通常基于 TCP/IP，能够在网络的任意两点之间传输文字、图片、音频、视频等数据。

HTTP 协议中的两个端点称为 **请求方** 和 **应答方** 。请求方通常就是 Web 浏览器，也叫 user agent，应答方是 Web 服务器，存储着网络上的大部分静态或动态的资源。

在浏览器和服务器之间还有一些 **中间人** 的角色，如 CDN、网关、代理等，它们也同样遵守 HTTP 协议，可以帮助用户更快速、更安全地获取资源。

HTTP 协议不是一个孤立的协议，需要下层很多其他协议的配合。最基本的是 TCP/IP，实现寻址、路由和可靠的数据传输，还有 DNS 协议实现对互联网上主机的定位查找。

对 HTTP 更准确的称呼是 **HTTP over TCP/IP** ，而另一个 **HTTP over SSL/TLS** 就是增加了安全功能的 HTTPS



## 键入网址再按下回车，后面究竟发生了什么？

抓包分析

![HTTP连接](https://s2.loli.net/2022/03/30/1oehYVXd3NGLbPQ.png)

#### 使用域名访问 Web 服务器

多出了一个访问 hosts 文件的动作，也就是本机的 DNS 解析

![DNS解析](https://s2.loli.net/2022/03/30/zJHRbL1dafEkiuj.png)

#### 真实的网络世界

第一个实验是最简单的场景，只有两个角色：浏览器和服务器，浏览器可以直接用 IP 地址找到服务器，两者直接建立 TCP 连接后发送 HTTP 报文通信。

第二个实验在浏览器和服务器之外增加了一个 DNS 的角色，浏览器不知道服务器的 IP 地址，所以必须要借助 DNS 的域名解析功能得到服务器的 IP 地址，然后才能与服务器通信。

真实的互联网世界要比这两个场景要复杂的多，我利用下面的这张图来做一个详细的说明。

![真实的网络世界](https://s2.loli.net/2022/03/30/vOYJ7mqrCLI5ezH.png)



1. HTTP 协议基于底层的 TCP/IP 协议，所以必须要用 IP 地址建立连接；
2. 如果不知道 IP 地址，就要用 DNS 协议去解析得到 IP 地址，否则就会连接失败；
3. 建立 TCP 连接后会顺序收发数据，请求方和应答方都必须依据 HTTP 规范构建和解析报文；
4. 为了减少响应时间，整个过程中的每一个环节都会有缓存，能够实现「短路」操作；
5. 虽然现实中的 HTTP 传输过程非常复杂，但理论上仍然可以简化成实验里的「两点」模型

## HTTP 报文是什么样子的？

HTTP 协议基本工作流程，也就是 **请求 - 应答**，**一发一收** 的模式

那么 HTTP 协议的核心部分是什么呢？

答案就是它 **传输的报文内容**。

HTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：

1. 起始行（start line）：描述请求或响应的基本信息；
2. 头部字段集合（header）：使用 key-value 形式更详细地说明报文；
3. 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。

![原始抓包的数据](https://s2.loli.net/2022/03/30/MsWfNtH36yIK2gb.png)

在这个浏览器发出的请求报文里，第一行 `GET / HTTP/1.1` 就是请求行，而后面的 Host、Connection 等等都属于 header，报文的最后是一个空白行结束，没有 body。

### 请求行

了解了 HTTP 报文的基本结构后，我们来看看请求报文里的起始行也就是 **请求行**（request line），它简要地描述了 **客户端想要如何操作服务器端的资源** 。

请求行由三部分构成：

1. 请求方法：是一个动词，如 GET/POST，表示对资源的操作；
2. 请求目标：通常是一个 URI，标记了请求方法要操作的资源；
3. 版本号：表示报文使用的 HTTP 协议版本。

例如

```markdown
GET / HTTP/1.1
```

在这个请求行里，`GET` 是请求方法，`/` 是请求目标，`HTTP/1.1` 是版本号，把这三部分连起来，意思就是「服务器你好，我想获取网站根目录下的默认文件，我用的协议版本号是 1.1，请不要用 1.0 或者 2.0 回复我。」

### 状态行

看完了请求行，我们再看响应报文里的起始行，在这里它不叫 **响应行**，而是叫 **状态行**（status line），意思是 **服务器响应的状态**。

比起请求行来说，状态行要简单一些，同样也是由三部分构成：

1. 版本号：表示报文使用的 HTTP 协议版本；
2. 状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误；
3. 原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。

例如：

```markdown
HTTP/1.1 200 OK
```

意思就是：「浏览器你好，我已经处理完了你的请求，这个报文使用的协议版本号是 1.1，状态码是 200，一切 OK。」

### 常用头字段

HTTP 协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：

1. 通用字段：在请求头和响应头里都可以出现；
2. 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；
3. 响应字段：仅能出现在响应头里，补充说明响应报文的信息；
4. 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。

#### Host

它属于 **请求字段**，只能出现在请求头里，它同时也是唯一一个 HTTP/1.1 规范里要求 **必须出现** 的字段

Host 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的 **路由重定向** 

#### User-Agent

**User-Agent** 是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面

#### Date

**Date** 字段是一个 **通用字段** ，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。

#### Server

**Server** 字段是 **响应字段**，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号

#### Content-Length

实体字段里要说的一个是 **Content-Length** ，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度

### 小结

1. HTTP 报文结构就像是「大头儿子」，由「起始行 + 头部 + 空行 + 实体」组成，简单地说就是「header+body」；
2. HTTP 报文可以没有 body，但必须要有 header，而且 header 后也必须要有空行，形象地说就是大头必须要带着脖子；
3. 请求头由「请求行 + 头部字段」构成，响应头由「状态行 + 头部字段」构成；
4. 请求行有三部分：请求方法，请求目标和版本号；
5. 状态行也有三部分：版本号，状态码和原因字符串；
6. 头部字段是 key-value 的形式，用 `:` 分隔，不区分大小写，顺序任意，除了规定的标准头，也可以任意添加自定义字段，实现功能扩展；
7. HTTP/1.1 里唯一要求必须提供的头字段是 Host，它必须出现在请求头里，标记虚拟主机名

## 应该如何理解请求方法？



目前 HTTP/1.1 规定了八种方法，单词 **都必须是大写的形式** ，我先简单地列把它们列出来，后面再详细讲解。

1. GET：获取资源，可以理解为读取或者下载数据；
2. HEAD：获取资源的元信息；
3. POST：向资源提交数据，相当于写入或上传数据；
4. PUT：类似 POST；
5. DELETE：删除资源；
6. CONNECT：建立特殊的连接隧道；
7. OPTIONS：列出可对资源实行的方法；
8. TRACE：追踪请求 - 响应的传输路径。

### GET/HEAD

**GET** 方法应该是 HTTP 协议里最知名的请求方法了，它的含义是请求 **从服务器获取资源** ，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据。

**HEAD** 方法与 GET 方法类似，也是请求从服务器获取资源，服务器的处理机制也是一样的，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的 **元信息** 。

### POST/PUT

POST 也是一个经常用到的请求方法，使用频率应该是仅次于 GET，应用的场景也非常多，只要向服务器发送数据，用的大多数都是 POST。

PUT 的作用与 POST 类似，也可以向服务器提交数据，但与 POST 存在微妙的不同，通常 POST 表示的是「新建（create）」的含义，而 PUT 则是「修改（update）」的含义。

### DELETE

指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。

### CONNECT

是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。

### OPTIONS

方法要求服务器列出可对资源实行的操作方法，**在响应头的 Allow 字段里返回** 。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持

### TRACE

多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用



## 你能写出正确的网址吗？

### URI 的格式

下面的这张图显示了 URI 最常用的形式，由 scheme、host:port、path 和 query 四个部分组成，但有的部分可以视情况省略。

![URI 的格式](https://s2.loli.net/2022/03/30/iequjRQfXUAxywV.png)

### URI 的基本组成

URI 第一个组成部分叫 **scheme** ，翻译成中文叫 **方案名** 或者 **协议名** ，表示 **资源应该使用哪种协议** 来访问。

最常见的当然就是 http 了，表示使用 HTTP 协议。另外还有 https ，表示使用经过加密、安全的 HTTPS 协议。此外还有其他不是很常见的 scheme，例如 ftp、ldap、file、news 等。

### 小结

1. URI 是用来唯一标记服务器上资源的一个字符串，通常也称为 URL；
2. URI 通常由 scheme、host:port、path 和 query 四个部分组成，有的可以省略；
3. scheme 叫方案名或者协议名，表示资源应该使用哪种协议来访问；
4. `host:port` 表示资源所在的主机名和端口号；
5. path 标记资源所在的位置；
6. query 表示对资源附加的额外要求；
7. 在 URI 里对 `@&/` 等特殊字符和汉字必须要做编码，否则服务器收到 HTTP 报文后会无法正确处理

## 响应状态码该怎么用？

### 状态码

**RFC 标准把状态码分成了五类** ，用数字的第一位表示分类，而 0~99 不用，这样状态码的实际可用范围就大大缩小了，由 000~999 变成了 100~599。

这五类的具体含义是：

- 1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
- 2××：成功，报文已经收到并被正确处理；
- 3××：重定向，资源位置发生变动，需要客户端重新发送请求；
- 4××：客户端错误，请求报文有误，服务器无法处理；
- 5××：服务器错误，服务器在处理请求时内部发生了错误。

目前 RFC 标准里总共有 41 个状态码

### 1××

1×× 类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。

我们偶尔能够见到的是 **101 Switching Protocols** 。它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。

### 2××

2×× 类状态码表示 **服务器收到并成功处理了客户端的请求** ，这也是客户端最愿意看到的状态码。

#### 200 OK

是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，如果是非 HEAD 请求，通常在响应头后都会有 body 数据

#### 204 No Content

是另一个很常见的成功状态码，它的含义与 `200 OK` 基本相同，但响应头后没有 body 数据。所以对于 Web 服务器来说，正确地区分 200 和 204 是很必要的

#### 206 Partial Content

是 HTTP 分块下载或断点续传的基础，在客户端发送 **范围请求**、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。

### 3××

3×× 类状态码表示 **客户端请求的资源发生了变动** ，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的 **重定向** ，包括著名的 301、302 跳转。

#### 301 Moved Permanently

俗称 **永久重定向** ，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问。

#### 302 Found

与 301 类似，曾经的描述短语是 **Moved Temporarily** ，俗称 **临时重定向** ，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。

301 和 302 都会在响应头里使用字段 **Location** 指明后续要跳转的 URI，最终的效果很相似，浏览器都会重定向到新的 URI。两者的根本区别在于语义，一个是 **永久** ，一个是 **临时** ，所以在场景、用法上差距很大。

比如，你的网站升级到了 HTTPS，原来的 HTTP 不打算用了，这就是永久的，所以要配置 301 跳转，把所有的 HTTP 流量都切换到 HTTPS

#### 304 Not Modified

它用于 `If-Modified-Since` 等条件请求，表示资源未修改，用于缓存控制。它不具有通常的跳转含义，但可以理解成 **重定向已到缓存的文件**（即缓存重定向）

### 4××

4×× 类状态码表示 **客户端发送的请求报文有误** ，服务器无法处理，它就是真正的 **错误码** 含义了。

#### 400 Bad Request

是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误，客户端看到 400 只会是一头雾水、不知所措。所以，在开发 Web 应用时应当尽量避免给客户端返回 400，而是要用其他更有明确含义的状态码。

#### 403 Forbidden

实际上不是客户端的请求出错，而是表示服务器禁止访问资源。原因可能多种多样，例如信息敏感、法律禁止等，如果服务器友好一点，可以在 body 里详细说明拒绝请求的原因，不过现实中通常都是直接给一个闭门羹。

#### 404 Not Found

可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端。但现在已经被「用滥了」，只要服务器不高兴就可以给出个 404，而我们也无从得知后面到底是真的未找到，还是有什么别的原因，某种程度上它比 403 还要令人讨厌

4×× 里剩下的一些代码较明确地说明了错误的原因

- 405 Method Not Allowed：不允许使用某些方法操作资源，例如不允许 POST 只能 GET；
- 406 Not Acceptable：资源无法满足客户端请求的条件，例如请求中文但只有英文；
- 408 Request Timeout：请求超时，服务器等待了过长的时间；
- 409 Conflict：多个请求发生了冲突，可以理解为多线程并发时的竞态；
- 413 Request Entity Too Large：请求报文里的 body 太大；
- 414 Request-URI Too Long：请求行里的 URI 太大；
- 429 Too Many Requests：客户端发送了太多的请求，通常是由于服务器的限连策略；
- 431 Request Header Fields Too Large：请求头某个字段或总体太大

###  5××

5×× 类状态码表示 **客户端请求报文正确，但服务器在处理时内部发生了错误** ，无法返回应有的响应数据，是服务器端的错误码。

#### 500 Internal Server Error

与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。虽然不利于调试，但能够防止黑客的窥探或者分析。

#### 501 Not Implemented

表示客户端请求的功能还不支持，这个错误码比 500 要温和一些，和即将开业，敬请期待的意思差不多，不过具体什么时候开业就不好说了。

#### 502 Bad Gateway

通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误，但具体的错误原因也是不知道的

#### 503 Service Unavailable

表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的「网络服务正忙，请稍后重试」的提示信息就是状态码 503。

503 是一个「临时」的状态，很可能过几秒钟后服务器就不那么忙了，可以继续提供服务，所以 503 响应报文里通常还会有一个 **Retry-After** 字段，指示客户端可以在多久以后再次尝试发送请求



## HTTP 有哪些特点？

1. HTTP 是灵活可扩展的，可以任意添加头字段实现任意功能；
2. HTTP 是可靠传输协议，基于 TCP/IP 协议“尽量”保证数据的送达；
3. HTTP 是应用层协议，比 FTP、SSH 等更通用功能更多，能够传输任意数据；
4. HTTP 使用了请求 - 应答模式，客户端主动发起请求，服务器被动回复请求；
5. HTTP 本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。





## HTTP有哪些优点？又有哪些缺点？

不过在正式开讲之前我还要提醒你一下，**今天的讨论范围仅限于 HTTP/1.1** ，所说的优点和缺点也仅针对 HTTP/1.1。实际上，专栏后续要讲的 HTTPS 和 HTTP/2 都是对 HTTP/1.1 优点的发挥和缺点的完善。

1. HTTP 最大的优点是简单、灵活和易于扩展；
2. HTTP 拥有成熟的软硬件环境，应用的非常广泛，是互联网的基础设施；
3. HTTP 是无状态的，可以轻松实现集群化，扩展性能，但有时也需要用 Cookie 技术来实现“有状态”；
4. HTTP 是明文传输，数据完全肉眼可见，能够方便地研究分析，但也容易被窃听；
5. HTTP 是不安全的，无法验证通信双方的身份，也不能判断报文是否被窜改；
6. HTTP 的性能不算差，但不完全适应现在的互联网，还有很大的提升空间。





## 海纳百川：HTTP 的实体数据

我会用连续的 8 讲的篇幅来详细解析 HTTP 协议里的各种头字段，包括定义、功能、使用方式、注意事项等等。学完了这些课程，你就可以完全掌握 HTTP 协议

在前面的基础篇里我们了解了 HTTP 报文的结构，知道一个 HTTP 报文是由 `header+body` 组成的。但那时我们主要研究的是 header，没有涉及到 body。所以，进阶篇的第一讲就从 HTTP 的 body 谈起。

### 数据类型与编码

幸运的是，早在 HTTP 协议诞生之前就已经有了针对这种问题的解决方案，不过它是用在电子邮件系统里的，让电子邮件可以发送 ASCII 码以外的任意数据，方案的名字叫做 **多用途互联网邮件扩展**（Multipurpose Internet Mail Extensions），简称为 MIME。

MIME 是一个很大的标准规范，但 HTTP 只是顺手牵羊取了其中的一部分，**用来标记 body 的数据类型** ，这就是我们平常总能听到的 **MIME type**。

MIME 把数据分成了 **八大类** ，每个大类下再细分出多个子类，形式是 `type/subtype` 的字符串，巧得很，刚好也符合了 HTTP 明文的特点，所以能够很容易地纳入 HTTP 头字段里。

这里简单列举一下在 HTTP 里经常遇到的几个类别：

1. text：即文本格式的可读数据，我们最熟悉的应该就是 `text/html` 了，表示超文本文档，此外还有纯文本 `text/plain`、样式表 `text/css` 等。
2. image：即图像文件，有 `image/gif`、`image/jpeg`、`image/png` 等。
3. `audio/video`：音频和视频数据，例如 `audio/mpeg`、`video/mp4` 等。
4. application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 `application/json`，`application/javascript`、`application/pdf` 等，另外，如果实在是不知道数据是什么类型，像刚才说的黑盒，就会是 `application/octet-stream`，**即不透明的二进制数据** 。

但仅有 MIME type 还不够，因为 HTTP 在传输时为了节约带宽，有时候还会 **压缩数据** ，为了不要让浏览器继续猜，还需要有一个 `Encoding type` ，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

比起 MIME type 来说，Encoding type 就少了很多，常用的只有下面三种：

1. gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
2. deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
3. br：一种专门为 HTTP 优化的新压缩算法（Brotli）。

### 数据类型使用的头字段

有了 MIME type 和 Encoding type，无论是浏览器还是服务器就都可以轻松识别出 body 的类型，也就能够正确处理数据了。

HTTP 协议为此定义了两个 `Accept` 请求头字段和两个 `Content` 实体头字段，用于客户端和服务器进行 **内容协商**。也就是说，**客户端用 Accept 头告诉服务器希望接收什么样的数据** ，**而服务器用 Content 头告诉客户端实际发送了什么样的数据**。

![协议交流](https://s2.loli.net/2022/03/31/1PDE6CB7S9HtJRL.png)

**Accept** 字段标记的是 **客户端可理解的 MIME type** ，可以用 `,` 做分隔符列出多个类型，让服务器有更多的选择余地，例如下面的这个头：

```http
Accept: text/html,application/xml,image/webp,image/png
```

这就是告诉服务器：我能够看懂 HTML、XML 的文本，还有 webp 和 png 的图片，请给我这四类格式的数据。

相应的，服务器会在响应报文里用头字段 `Content-Type` 告诉实体数据的真实类型：

```http
Content-Type: text/html
Content-Type: image/png
```

这样浏览器看到报文里的类型是 `text/html` 就知道是 HTML 文件，会调用排版引擎渲染出页面，看到 `image/png` 就知道是一个 PNG 文件，就会在页面上显示出图像。

**Accept-Encoding** 字段标记的是 **客户端支持的压缩格式** ，例如上面说的 gzip、deflate 等，同样也可以用 `,` 列出多个，服务器可以选择其中一种来压缩数据，实际使用的压缩格式放在响应头字段 **Content-Encoding** 里。

```http
Accept-Encoding: gzip, deflate, br
Content-Encoding: gzip
```

不过这两个字段是可以省略的，如果请求报文里没有 Accept-Encoding 字段，就表示客户端不支持压缩数据；如果响应报文里没有 Content-Encoding 字段，就表示响应数据没有被压缩。

### 语言类型与编码

MIME type 和 Encoding type 解决了计算机理解 body 数据的问题，但互联网遍布全球，不同国家不同地区的人使用了很多不同的语言，虽然都是 `text/html` ，但如何让浏览器显示出每个人都可理解可阅读的语言文字呢？

这实际上就是 **国际化** 的问题。HTTP 采用了与数据类型相似的解决方案，又引入了两个概念：语言类型与字符集。

所谓的 **语言类型** 就是人类使用的自然语言，例如英语、汉语、日语等，而这些自然语言可能还有下属的地区性方言，所以在需要明确区分的时候也要使用 `type-subtype` 的形式，不过这里的格式与数据类型不同， **分隔符不是 `/` ， 而是 `-`** 。

举几个例子：en 表示任意的英语，en-US 表示美式英语，en-GB 表示英式英语，而 zh-CN 就表示我们最常使用的汉语。

关于自然语言的计算机处理还有一个更麻烦的东西叫做 **字符集** 

在计算机发展的早期，各个国家和地区的人们「各自为政」，发明了许多字符编码方式来处理文字，比如英语世界用的 ASCII、汉语世界用的 GBK、BIG5，日语世界用的 Shift_JIS 等。同样的一段文字，用一种编码显示正常，换另一种编码后可能就会变得一团糟。

所以后来就出现了 Unicode 和 UTF-8，把世界上所有的语言都容纳在一种编码方案里，UTF-8 编码 的 Unicode 也成为了互联网上的标准字符集

### 语言类型使用的头字段

同样的，HTTP 协议也使用 Accept 请求头字段和 Content 实体头字段，用于客户端和服务器就语言与编码进行 **内容协商** 。

**Accept-Language** 字段标记了 **客户端可理解的自然语言** ，也允许用 `,` 做分隔符列出多个类型，例如：

```http
Accept-Language: zh-CN, zh, en
```

这个请求头会告诉服务器：最好给我 zh-CN 的汉语文字，如果没有就用其他的汉语方言，如果还没有就给英文。

相应的，服务器应该在响应报文里用头字段 **Content-Language** 告诉客户端实体数据使用的实际语言类型：

```http
Content-Language: zh-CN
```

字符集在 HTTP 里使用的请求头字段是 **Accept-Charset** ，但响应头里却没有对应的 Content-Charset，而是在**Content-Type** 字段的数据类型后面用 `charset=xxx` 来表示，这点需要特别注意。

例如，浏览器请求 GBK 或 UTF-8 的字符集，然后服务器返回的是 UTF-8 编码，就是下面这样：

```http
Accept-Charset: gbk, utf-8
Content-Type: text/html; charset=utf-8
```

### 内容协商的质量值

在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，还可以用一种特殊的 `q` 参数表示权重来设定优先级，这里的 `q` 是 `quality factor`的意思。

权重的最大值是 1，最小值是 0.01，默认值是 1，如果值是 0 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个 `;` ，然后是 `q=value` 。

这里要提醒的是 `;` 的用法，在大多数编程语言里 `;` 的断句语气要强于 `,` ，而在 HTTP 的内容协商里却恰好反了过来，`;` 的意义是小于 `,` 的。

例如下面的 Accept 字段：

```http
Accept: text/html,application/xml;q=0.9,*/*;q=0.8
```

它表示浏览器最希望使用的是 HTML 文件，权重是 1，其次是 XML 文件，权重是 0.9，最后是任意数据类型，权重是 0.8。服务器收到请求头后，就会计算权重，再根据自己的实际情况优先输出 HTML 或者 XML。

### 内容协商的结果

内容协商的过程是不透明的，每个 Web 服务器使用的算法都不一样。但有的时候，服务器会在响应头里多加一个**Vary** 字段，记录服务器在内容协商时参考的请求头字段，给出一点信息，例如：

```http
Vary: Accept-Encoding,User-Agent,Accept
```

这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文。

Vary 字段可以认为是响应报文的一个特殊的 **版本标记** 。每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化。也就是说，同一个 URI 可能会有多个不同的「版本」，**主要用在传输链路中间的代理服务器实现缓存服务** 

### 小结

![数据类型和语言类型](https://s2.loli.net/2022/03/31/zPwNf5pY7mO3jRC.png)

1. 数据类型表示实体数据的内容是什么，使用的是 MIME type，相关的头字段是 Accept 和 Content-Type；
2. 数据编码表示实体数据的压缩方式，相关的头字段是 Accept-Encoding 和 Content-Encoding；
3. 语言类型表示实体数据的自然语言，相关的头字段是 Accept-Language 和 Content-Language；
4. 字符集表示实体数据的编码方式，相关的头字段是 Accept-Charset 和 Content-Type；
5. 客户端需要在请求头里使用 Accept 等头字段与服务器进行内容协商，要求服务器返回最合适的数据；
6. Accept 等头字段可以用 `,` 顺序列出多个可能的选项，还可以用 `;q=` 参数来精确指定权重。



## 把大象装进冰箱：HTTP 传输大文件的方法

上次我们谈到了 HTTP 报文里的 body，知道了 HTTP 可以传输很多种类的数据，不仅是文本，也能传输图片、音频和视频。

早期互联网上传输的基本上都是只有几 K 大小的文本和小图片，现在的情况则大有不同。网页里包含的信息实在是太多了，随随便便一个主页 HTML 就有可能上百 K，高质量的图片都以 M 论，更不要说那些电影、电视剧了，几 G、几十 G 都有可能。

相比之下，100M 的光纤固网或者 4G 移动网络在这些大文件的压力下都变成了 「小水管」，无论是上传还是下载，都会把网络传输链路挤的「满满当当」。

所以，**如何在有限的带宽下高效快捷地传输这些大文件就成了一个重要的课题** 。这就好比是已经打开了冰箱门（建立连接），该怎么把大象（文件）塞进去再关上门（完成传输）呢？

### 数据压缩

还记得上一讲中说到的 **数据类型与编码** 吗？如果你还有印象的话，肯定能够想到一个最基本的解决方案，那就是 **数据压缩** ，把大象变成小猪佩奇，再放进冰箱。

通常浏览器在发送请求时都会带着 **Accept-Encoding** 头字段，里面是 **浏览器支持的压缩格式列表** ，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进 **Content-Encoding** 响应头里，再把原数据压缩后发给浏览器。

如果压缩率能有 50%，也就是说 100K 的数据能够压缩成 50K 的大小，那么就相当于在带宽不变的情况下网速提升了一倍，加速的效果是非常明显的。

不过这个解决方法也有个缺点，gzip 等压缩算法通常只对文本文件有较好的压缩率，而图片、音频视频等多媒体数据本身就已经是高度压缩的，再用 gzip 处理也不会变小（甚至还有可能会增大一点），所以它就失效了。

不过数据压缩在处理文本的时候效果还是很好的，所以各大网站的服务器都会使用这个手段作为保底。例如，在 Nginx 里就会使用 `gzip on` 指令，启用对 `text/html` 的压缩

### 分块传输

在数据压缩之外，还能有什么办法来解决大文件的问题呢？

压缩是把大文件整体变小，我们可以反过来思考，如果大文件整体不能变小，那就把它 **拆开** ，分解成多个小块，把这些小块分批发给浏览器，浏览器收到后再组装复原。

这样浏览器和服务器都不用在内存里保存文件的全部，每次只收发一小部分，网络也不会被大文件长时间占用，内存、带宽等资源也就节省下来了。

这种 **化整为零** 的思路在 HTTP 协议里就是 **chunked** 分块传输编码，在响应报文里用头字段 **Transfer-Encoding: chunked** 来表示，意思是报文里的 body 部分不是一次性发过来的，而是分成了许多的块（chunk）逐个发送。

这就好比是用魔法把大象变成乐高积木，拆散了逐个装进冰箱，到达目的地后再施法拼起来满血复活。

**分块传输也可以用于流式数据** ，例如由数据库动态生成的表单页面，这种情况下 **body 数据的长度是未知的** ，无法在头字段 **Content-Length** 里给出确切的长度，所以也只能用 chunked 方式分块发送。

`Transfer-Encoding: chunked` 和 `Content-Length` 这两个字段是 **互斥的** ，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked），这一点你一定要记住。

下面我们来看一下分块传输的编码规则，其实也很简单，同样采用了明文的方式，很类似响应头。

1. 每个分块包含两个部分，长度头和数据块；
2. 长度头是以 CRLF（回车换行，即 `\r\n` ）结尾的一行明文，用 16 进制数字表示长度；
3. 数据块紧跟在长度头后，最后也用 CRLF 结尾，但数据不包含 CRLF；
4. 最后用一个长度为 0 的块表示结束，即 `0\r\n\r\n`。

听起来好像有点难懂，看一下图就好理解了：

![25e7b09cf8cb4eaebba42b4598192410.25e7b09c](https://s2.loli.net/2022/03/31/jvHDiR4M1L26bnE.png)



### 范围请求

有了分块传输编码，服务器就可以轻松地收发大文件了，但对于上 G 的超大文件，还有一些问题需要考虑。

比如，你在看当下正热播的某穿越剧，想跳过片头，直接看正片，或者有段剧情很无聊，想拖动进度条快进几分钟，**这实际上是想获取一个大文件其中的片段数据** ，而分块传输并没有这个能力。

HTTP 协议为了满足这样的需求，提出了 **范围请求** （range requests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是 **客户端的「化整为零**」 。

范围请求不是 Web 服务器必备的功能，可以实现也可以不实现，所以服务器必须在响应头里使用字段 **Accept-Ranges: bytes** 明确告知客户端：「我是支持范围请求的」。

如果不支持的话该怎么办呢？服务器可以发送 `Accept-Ranges: none` ，或者干脆不发送 `Accept-Ranges` 字段，这样客户端就认为服务器没有实现范围请求功能，只能老老实实地收发整块文件了。

请求头 **Range** 是 HTTP 范围请求的专用字段，格式是 **bytes=x-y**，其中的 x 和 y 是以字节为单位的数据范围。

要注意 x、y 表示的是 **偏移量** ，范围必须从 0 计数，例如前 10 个字节表示为 `0-9`，第二个 10 字节表示为 `10-19` ，而 `0-10` 实际上是前 11 个字节。

Range 的格式也很灵活，起点 x 和终点 y 可以省略，能够很方便地表示正数或者倒数的范围。**假设文件是 100 个字节** ，那么：

- `0-` 表示从文档起点到文档终点，相当于 `0-99` ，即整个文件；
- `10-` 是从第 10 个字节开始到文档末尾，相当于 `10-99`；
- `-1` 是文档的最后一个字节，相当于 `99-99` ；
- `-10` 是从文档末尾倒数 10 个字节，相当于 `90-99` 。

服务器收到 Range 字段后，需要做四件事。

1. 第一，它必须检查范围是否合法

   比如文件只有 100 个字节，但请求 `200-300` ，这就是范围越界了。服务器就会返回状态码 **416**，意思是「你的范围请求有误，我无法处理，请再检查一下」。

2. 第二，如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码 **206 Partial Content** ，和 200 的意思差不多，但表示 body 只是原数据的一部分。

3. 第三，服务器要添加一个响应头字段 **Content-Range**

   告诉片段的实际偏移量和资源的总大小，格式是 **bytes x-y/length** ，与 Range 头区别在没有 `=`，范围后多了总长度。例如，对于 `0-10` 的范围请求，值就是 `bytes 0-10/100` 。

4. 最后剩下的就是发送数据了，直接把片段用 TCP 发给客户端，一个范围请求就算是处理完了。



### 多段数据

刚才说的范围请求一次只获取一个片段，其实它还支持在 Range 头里使用多个 `x-y`，一次性获取多个片段数据。

这种情况需要使用一种特殊的 MIME 类型：**multipart/byteranges**，表示报文的 body 是由多段字节序列组成的，并且还要用一个参数 **boundary=xxx** 给出段之间的分隔标记。

多段数据的格式与分块传输也比较类似，但它需要用分隔标记 boundary 来区分不同的片段

### 小结

今天我们学习了 HTTP 传输大文件相关的知识，在这里做一下简单小结：

1. 压缩 HTML 等文本文件是传输大文件最基本的方法；
2. 分块传输可以流式收发数据，节约内存和带宽，使用响应头字段 `Transfer-Encoding: chunked` 来表示，分块的格式是 16 进制长度头 + 数据块；
3. 范围请求可以只获取部分数据，即 **分块请求**，实现视频拖拽或者断点续传，使用请求头字段 `Range` 和响应头字段 `Content-Range` ，响应状态码必须是 206；
4. 也可以一次请求多个范围，这时候响应报文的数据类型是 `multipart/byteranges` ，body 里的多个部分会用 boundary 字符串分隔。

## 排队也要讲效率：HTTP 的连接管理

HTTP 的性能问题，用了六个字来概括：**不算差，不够好** 。同时，我也谈到了 **队头阻塞**

### 短连接

HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程也采用了简单的 **请求 - 应答** 方式。

它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。

因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为 **短连接** （short-lived connections）。早期的 HTTP 协议也被称为是 **无连接** 的协议。

短连接的缺点相当严重，因为在 TCP 协议里，建立连接和关闭连接都是非常“昂贵”的操作。TCP 建立连接要有 **三次握手**，发送 3 个数据包，需要 1 个 RTT；关闭连接是 **四次挥手**，4 个数据包需要 2 个 RTT（一个来回就是 1 RTT）。

而 HTTP 的一次简单请求 - 响应通常只需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是`3÷5=60%` ，有三分之二的时间被浪费掉了，传输效率低得惊人。

![54315ed9ac37fbc6547258040f00a80c.54315ed9](https://s2.loli.net/2022/03/31/XsRf6YIurknagzE.png)

单纯地从理论上讲，TCP 协议你可能还不太好理解，我就拿打卡考勤机来做个形象的比喻吧。

假设你的公司买了一台打卡机，放在前台，因为这台机器比较贵，所以专门做了一个保护罩盖着它，公司要求每次上下班打卡时都要先打开盖子，打卡后再盖上盖子。

可是偏偏这个盖子非常牢固，打开关闭要费很大力气，打卡可能只要 1 秒钟，而开关盖子却需要四五秒钟，**大部分时间都浪费在了毫无意义的开关盖子操作上了** 。

可想而知，平常还好说，一到上下班的点在打卡机前就会排起长队，每个人都要重复“开盖 - 打卡 - 关盖”的三个步骤，你说着急不着急。

在这个比喻里，打卡机就相当于服务器，盖子的开关就是 TCP 的连接与关闭，而每个打卡的人就是 HTTP 请求，很显然，短连接的缺点严重制约了服务器的服务能力，导致它无法处理更多的请求。

### 长连接

针对短连接暴露出的缺点，HTTP 协议就提出了 **长连接** 的通信方式，也叫 **持久连接** （persistent connections）、**连接保活**（keep alive）、**连接复用**（connection reuse）。

其实解决办法也很简单，用的就是 **成本均摊** 的思路，既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个请求 - 应答均摊到多个请求 - 应答上。

这样虽然不能改善 TCP 的连接效率，但基于 **分母效应** ，每个请求 - 应答的无效时间就会降低不少，整体传输效率也就提高了。

![57b3d80234a1f1b8c538a376aa01d3b4.57b3d802](https://s2.loli.net/2022/03/31/Kk8lSqaMmbDthvZ.png)

在短连接里发送了三次 HTTP请求 - 应答，每次都会浪费 60% 的 RTT 时间。而在长连接的情况下，同样发送三次请求，因为只在第一次时建立连接，在最后一次时关闭连接，所以浪费率就是 `3÷9≈33%` ，降低了差不多一半的时间损耗。显然，如果在这个长连接上发送的请求越多，分母就越大，利用率也就越高。

继续用刚才的打卡机的比喻，公司也觉得这种反复「开盖 - 打卡 - 关盖」的操作太反人类了，于是颁布了新规定，早上打开盖子后就不用关上了，可以自由打卡，到下班后再关上盖子。

这样打卡的效率（即服务能力）就大幅度提升了，原来一次打卡需要五六秒钟，现在只要一秒就可以了，上下班时排长队的景象一去不返，大家都开心

### 连接相关的头字段

由于长连接对性能的改善效果非常显著，所以在 HTTP/1.1 中的连接都会 **默认启用长连接** 。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的 TCP 连接，也就是长连接，在这个连接上收发数据。

当然，我们也可以在请求头里明确地要求使用长连接机制，使用的字段是 **Connection** ，值是 **keep-alive** 。

不过不管客户端是否显式要求长连接，如果服务器支持长连接，它总会在响应报文里放一个 **Connection: keep-alive** 字段，告诉客户端：我是支持长连接的，接下来就用这个 TCP 一直收发数据吧

### 队头阻塞

看完了短连接和长连接，接下来就要说到著名的 **队头阻塞**（Head-of-line blocking，也叫队首阻塞）了。

**队头阻塞与短连接和长连接无关** ，而是由 HTTP 基本的 **请求 - 应答** 模型所导致的。

因为 HTTP 规定报文必须是 **一发一收** ，这就形成了一个先进先出的 **串行队列** 。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。

如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本。

![队头阻塞](C:/Users/hanbo/Desktop/6a6d30a89fb085d5f1773a887aaf5572.6a6d30a8.png)

还是用打卡机做个比喻。

上班的时间点上，大家都在排队打卡，可这个时候偏偏最前面的那个人遇到了打卡机故障，怎么也不能打卡成功，急得满头大汗。等找人把打卡机修好，后面排队的所有人全迟到了。

### 性能优化

因为 **请求 - 应答** 模型不能变，所以队头阻塞问题在 HTTP/1.1 里无法解决，只能缓解，有什么办法呢？

公司里可以再多买几台打卡机放在前台，这样大家可以不用挤在一个队伍里，分散打卡，一个队伍偶尔阻塞也不要紧，可以改换到其他不阻塞的队伍。

这在 HTTP 里就是 **并发连接**（concurrent connections），**也就是同时对一个域名发起多个长连接，用数量来解决质量的问题** 

所以，HTTP 协议建议客户端使用并发，但不能「滥用」并发。RFC2616 里明确限制每个客户端最多并发 2 个连接。不过实践证明这个数字实在是太小了，众多浏览器都「无视」标准，把这个上限提高到了 6~8。后来修订的 RFC7230 也就顺水推舟，取消了这个 2 的限制。

但并发连接所压榨出的性能也跟不上高速发展的互联网无止境的需求，还有什么别的办法吗？

公司发展的太快了，员工越来越多，上下班打卡成了迫在眉睫的大问题。前台空间有限，放不下更多的打卡机了，怎么办？那就多开几个打卡的地方，每个楼层、办公区的入口也放上三四台打卡机，把人进一步分流，不要都往前台挤。

这个就是 **域名分片**（domain sharding）技术，还是用数量来解决质量的思路。

HTTP 协议和浏览器不是限制并发连接数量吗？好，那我就多开几个域名，比如 shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器 `www.chrono.com` ，这样实际长连接的数量就又上去了，真是美滋滋。不过实在是有点上有政策，下有对策的味道。

### 小结

1. 早期的 HTTP 协议使用短连接，收到响应后就立即关闭连接，效率很低；
2. HTTP/1.1 默认启用长连接，在一个连接上收发多个请求响应，提高了传输效率；
3. 服务器会发送 `Connection: keep-alive` 字段表示启用了长连接；
4. 报文头里如果有 `Connection: close` 就意味着长连接即将关闭；
5. 过多的长连接会占用服务器资源，所以服务器会用一些策略有选择地关闭长连接；
6. 队头阻塞问题会导致性能下降，可以用 **并发连接** 和 **域名分片** 技术缓解。



## 四通八达：HTTP 的重定向和跳转

为了实现在互联网上构建超链接文档系统的设想，蒂姆·伯纳斯 - 李发明了万维网，使用 HTTP 协议传输 **超文本** ，让全世界的人都能够自由地共享信息。

**超文本** 里含有 **超链接** ，可以从一个超文本跳跃到另一个超文本，对线性结构的传统文档是一个根本性的变革。

**能够使用超链接在网络上任意地跳转** 也是万维网的一个关键特性。

这样的跳转动作是由浏览器的使用者主动发起的，可以称为 **主动跳转** ，但还有一类跳转是由服务器来发起的，浏览器使用者无法控制，相对地就可以称为 **被动跳转** ，这在 HTTP 协议里有个专门的名词，叫做 **重定向**（Redirection）。

### 重定向的过程

重定向是服务器发起的跳转，要求客户端改用新的 URI 重新发送请求，通常会自动进行，用户是无感知的；

### 重定向状态码

**301** 俗称 **永久重定向**（Moved Permanently）

**302** 俗称 **临时重定向**（Moved Temporarily），意思是原 URI 处于 **临时维护** 状态，新的 URI 是起顶包作用的临时工

301/302 是最常用的重定向状态码，在 3×× 里剩下的几个还有：

- 303 See Other：类似 302，但要求重定向后的请求改为 GET 方法，访问一个结果页面，避免 POST/PUT 重复操作；
- 307 Temporary Redirect：类似 302，但重定向后请求里的方法和实体不允许变动，含义比 302 更明确；
- 308 Permanent Redirect：类似 307，不允许重定向后的请求变动，但它是 301 永久重定向的含义。

不过这三个状态码的接受程度较低，有的浏览器和服务器可能不支持，开发时应当慎重，测试确认浏览器的实际效果后才能使用。

### 小结

今天我们学习了 HTTP 里的重定向和跳转，简单小结一下这次的内容：

1. 重定向是服务器发起的跳转，要求客户端改用新的 URI 重新发送请求，通常会自动进行，用户是无感知的；
2. 301/302 是最常用的重定向状态码，分别是 **永久重定向** 和 **临时重定向** ；
3. 响应头字段 Location 指示了要跳转的 URI，可以用绝对或相对的形式；
4. 重定向可以把一个 URI 指向另一个 URI，也可以把多个 URI 指向同一个 URI，用途很多；
5. 使用重定向时需要当心性能损耗，还要避免出现循环跳转。



## 让我知道你是谁：HTTP 的 Cookie 机制

前面说到 HTTP 是 「无状态」的，这既是优点也是缺点。优点是服务器没有状态差异，**可以很容易地组成集群** ，而缺点就是无法支持需要记录状态的事务操作。

好在 HTTP 协议是可扩展的，后来发明的 Cookie 技术，给 HTTP 增加了「记忆能力」

### 什么是 Cookie？

HTTP 的 Cookie 机制也是一样的道理，**既然服务器记不住，那就在外部想办法记住** 。相当于是服务器给每个客户端都贴上一张小纸条，上面写了一些只有服务器才能理解的数据，需要的时候客户端把这些信息发给服务器，服务器看到 Cookie，就能够认出对方是谁了

### Cookie 的工作过程

那么，Cookie 这张小纸条是怎么传递的呢？

这要用到两个字段：响应头字段 **Set-Cookie** 和请求头字段 **Cookie**。

当用户通过浏览器第一次访问服务器的时候，服务器肯定是不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是 **key=value**，然后放进 Set-Cookie 字段里，随着响应报文一同发给浏览器。

浏览器收到响应报文，看到里面有 Set-Cookie，知道这是服务器给的身份标识，于是就保存起来，下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。

因为第二次请求里面有了 Cookie 字段，服务器就知道这个用户不是新人，之前来过，就可以拿出 Cookie 里的值，识别出用户的身份，然后提供个性化的服务。

不过因为服务器的记忆能力实在是太差，一张小纸条经常不够用。所以，服务器有时会在响应头里添加多个 Set-Cookie，存储多个 `key=value`。但浏览器这边发送时不需要用多个 Cookie 字段，只要在一行里用 `;` 隔开就行。

我画了一张图来描述这个过程，你看过就能理解了。

![cookies](https://s2.loli.net/2022/03/31/BZIJ7wYcPN2Lgjl.png)

从这张图中我们也能够看到，Cookie 是由浏览器负责存储的，而不是操作系统。所以，它是浏览器绑定的，只能在本浏览器内生效。

如果你换个浏览器或者换台电脑，新的浏览器里没有服务器对应的 Cookie，就好像是脱掉了贴着纸条的衣服，健忘的服务器也就认不出来了，只能再走一遍 Set-Cookie 流程。

### Cookie 的属性

说到这里，你应该知道了，**Cookie 就是服务器委托浏览器存储在客户端里的一些数据** ，而这些数据通常都会记录用户的关键识别信息。所以，就需要在 `key=value` 外再用一些手段来保护，防止外泄或窃取，这些手段就是 Cookie 的属性。

#### Cookie 的生命周期

首先，我们应该 **设置 Cookie 的生存周期** ，也就是它的有效期，让它只能在一段时间内可用，就像是食品的保鲜期，一旦超过这个期限浏览器就认为是 Cookie 失效，在存储里删除，也不会发送给服务器。

Cookie 的有效期可以使用 `Expires` 和 `Max-Age` 两个属性来设置。

- **Expires** 俗称 **过期时间**，用的是 **绝对时间点** ，可以理解为 **截止日期**（deadline）。
- **Max-Age** 用的是相对时间，单位是秒，浏览器用收到报文的时间点再加上 Max-Age，就可以得到失效的绝对时间。

Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，**但浏览器会优先采用 Max-Age 计算失效期** 。

#### Cookie 的作用域

**设置 Cookie 的作用域** ，**让浏览器仅发送给特定的服务器和 URI** ，避免被其他网站盗用。

作用域的设置比较简单，**Domain** 和 **Path** 指定了 Cookie 所属的域名和路径，浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分，对比 Cookie 的属性。如果不满足条件，就不会在请求头里发送 Cookie。

#### Cookie 的安全性

最后要考虑的就是 **Cookie 的安全性** 了，尽量不要让服务器以外的人看到。

写过前端的同学一定知道，在 JS 脚本里可以用 `document.cookie` 来读写 Cookie 数据，这就带来了安全隐患，有可能会导致 **跨站脚本（XSS）** 攻击窃取数据。

- **HttpOnly**

  属性 **HttpOnly** 会告诉浏览器，此 Cookie 只能通过浏览器 HTTP 协议传输，**禁止其他方式访问** ，浏览器的 JS 引擎就会禁用 `document.cookie` 等一切相关的 API，脚本攻击也就无从谈起了。

- **SameSite**

  可以防范 **跨站请求伪造（XSRF）攻击** ：设置成

  `SameSite=Strict` ：可以严格限定 Cookie 不能随着跳转链接跨站发送

  `SameSite=Lax`：则略宽松一点，允许 `GET/HEAD` 等安全方法，但禁止 POST 跨站发送。

  还有一个 None，不限制

- **Secure**

  表示这个 Cookie **仅能用 HTTPS 协议加密传输** ，明文的 HTTP 协议会禁止发送。但 Cookie 本身不是加密的，浏览器里还是以明文的形式存在。

### 小结

今天我们学习了 HTTP 里的 Cookie 知识。虽然现在已经出现了多种 `Local Web Storage` 技术，能够比 Cookie 存储更多的数据，但 Cookie 仍然是最通用、兼容性最强的客户端数据存储手段。

简单小结一下今天的内容：

1. Cookie 是服务器委托浏览器存储的一些数据，让服务器有了记忆能力；
2. 响应报文使用 Set-Cookie 字段发送 key=value 形式的 Cookie 值；
3. 请求报文里用 Cookie 字段发送多个 Cookie 值；
4. 为了保护 Cookie，还要给它设置有效期、作用域等属性，常用的有 Max-Age、Expires、Domain、HttpOnly 等；
5. Cookie 最基本的用途是身份识别，实现有状态的会话事务。

还要提醒你一点，因为 Cookie 并不属于 HTTP 标准（RFC6265，而不是 RFC2616/7230），所以语法上与其他字段不太一致，使用的分隔符是 `;` ，与 Accept 等字段的 `,` 不同，小心不要弄错了。

## 生鲜速递：HTTP 的缓存控制

缓存（Cache）是计算机领域里的一个重要概念，是优化系统性能的利器。

由于链路漫长，网络时延不可控，浏览器使用 HTTP 获取资源的成本较高。所以，非常有必要把来之不易的数据缓存起来，下次再请求的时候尽可能地 **复用** 。这样，就可以 **避免多次请求 - 应答的通信成本，节约网络带宽** ，也可以加快响应速度。

基于 「请求 - 应答」模式的特点，可以大致分为 **客户端缓存** 和 **服务器端缓存** ，因为服务器端缓存经常与代理服务「混搭」在一起，所以今天我先讲客户端——也就是 **浏览器的缓存 ** 

### 服务器的缓存控制

为了更好地说明缓存的运行机制，下面我用「生鲜速递」作为比喻，看看缓存是如何工作的。

夏天到了，天气很热。你想吃西瓜消暑，于是打开冰箱，但很不巧，冰箱是空的。不过没事，现在物流很发达，给生鲜超市打个电话，不一会儿，就给你送来一个 8 斤的沙瓤大西瓜，上面还贴着标签：「**保鲜期 5 天**」。好了，你把它放进冰箱，想吃的时候随时拿出来。

在这个场景里：

- 生鲜超市：就是 Web 服务器
- 你：就是浏览器
- 冰箱：就是浏览器内部的缓存

整个流程翻译成 HTTP 就是：

1. 浏览器发现缓存无数据，于是发送请求，向服务器获取资源；
2. 服务器响应请求，返回资源，同时标记资源的有效期；
3. 浏览器缓存资源，等待下次重用。

![缓存](https://s2.loli.net/2022/03/31/5xIe9pVQm1gaP32.png)



